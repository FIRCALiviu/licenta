\chapter{Preliminarii}

O să explicăm tehnologiile folosite, dar și anumite noțiuni utilizate în acest studiu.

Cel mai învechit LLM folosit este GPT 4 \cite{gpt4}. Modelul a fost publicat în martie 2023, și faptul că este cel mai vechi va fi important ulterior.

Al doilea LLM „învechit” este DeepSeek-V3, care a fost publicat în decembrie 2024 \cite{v3}. A introdus diferite mecanisme care i-au permis să fie mai ieftin decât
competiția sa, dar tot păstrând o performanță similară.

Al treilea LLM studiat este DeepSeek-R1, care a fost publicat în ianuarie 2025 \cite{r1}. În contrast cu GPT 4, DeepSeek-V3 și GPT 4.1, acesta este un thinking model,
adică LLM-ul este forțat să „gândească” înainte să dea un răspuns utilizatorului. Partea de gândire constă în încercarea a mai multor abordări, dar și
un spirit mai critic, care este mai greu de convins. Tipic vorbind, LLM-ul încearcă să separe problema în mai multe etape de rezolvare în partea de gândire.
Noutatea adusă de acest LLM este că e mult mai ieftin decât competiția lui, dar și mai performant (decât LLM-urile de gândire care au fost publicate înaintea lui).

Gemini 2.5 este al doilea cel mai nou LLM utilizat în acest studiu \cite{gemini}. Modelul a fost publicat în martie 2025. Nu sunt foarte multe lucruri cunoscute despre el, în afară că și el este
un thinking model, și că a ridicat performanța state-of-the-art la mai multe capacități, inclusiv matematică \cite{gemini}. Există două variante: cea pro și cea flash,
evident, varianta pro este cea mai scumpă.

Cel mai recent LLM studiat este GPT 4.1 \cite{gpt41}. Modelul a fost publicat în aprilie 2025 și are o performanță mult mai bună decât predecesorul său, GPT 4o.

Acum că am introdus tehnologiile folosite, trebuie și să precizăm noțiunile folosite:
\begin{itemize}
\item Inferența: în acest context, se referă la procesul prin care modelul generează un răspuns pornind de la o interogare dată de la utilizator.
Un lucru important de notat este că s-a observat că mai multe resurse alocate inferenței (mai multe cuvinte generate,
răspuns mai "gândit" și detaliat)
rezultă în performanță mai bună. De exemplu, s-a arătat că dacă instruiești un LLM să se gândească pas cu pas și nu să răspundă pur și simplu, performanța crește \cite{cot}.

\item Antrenarea: în acest context, se referă la procesul de a lua un model neinițializat, care nu știe nici măcar să vorbească, și să
îl îmbunătățești pe baza anumitor date (ar putea fi text de pe internet, cărți, și toate documentele scrise în text). Această îmbunătățire se face schimbând parametrii modelului.

\item Fine-tuning: se referă la procesul de a lua un model deja antrenat și de a-i schimba parametrii a doua oară, pentru a-l face mai bun
pentru o anumită sarcină. Lucrul acesta ar merge bine, de exemplu, dacă luăm un LLM care a fost antrenat să facă „orice” și îl specializăm să
răspundă la emailuri. Ideea de fine-tuning este interesantă pentru acest studiu, pentru că dacă am face un fine-tuning pe LLM-urile studiate,
ar fi foarte probabil ca performanța să crească puțin.
\end{itemize}

O premisă \textbf{importantă} a acestui studiu este că dacă distanța medie între nota adevărată și nota asignată (mean absolute error, sau MAE) de LLM este sub 5 puncte din 100,
atunci acuratețea este judecată ca fiind destul de bună pentru a corecta notele de bac.
Am luat ca metrică de performanță MAE pentru că a fost folosită înainte pentru a măsura performanța LLM-urilor la notarea lucrărilor \cite{golchin}.
Este și mai intuitiv să luăm MAE în loc de MSE (mean squared error) în acest caz, pentru că și erorile mici sunt importante. De exemplu, o diferență
mică între așteptările studentului și nota primită ar
putea face studentul să depună o contestație. Motivul pentru care pragul pentru reușită este setat la o eroare de 5 puncte din 100 este pentru că:
\begin{enumerate}
\item Chiar dacă baremul este destul de obiectiv, există totuși o mică parte de interpretare subiectivă
\item Până în 2021, o notă trebuia să se schimbe cu cel puțin 0.5 puncte din 10 ca să fie admisă contestația
\end{enumerate}


