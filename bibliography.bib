@misc{gpt4,
  author       = {OpenAI},
  title        = {GPT-4 Technical Report},
  year         = 2023,
  url          = {https://arxiv.org/abs/2303.08774},
  note         = {arXiv:2303.08774}
}

@misc{gemini,
  author       = {Google DeepMind},
  title        = {Gemini 2.5: Our most intelligent AI model},
  year         = {2025},
  month        = mar,
  url          = {https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025},
  note         = {Accesat : Iunie 2025}
}

@misc{gpt41,
  author       = {OpenAI},
  title        = {Introducing GPT-4.1 in the API},
  year         = {2025},
  month        = {April},
  url          = {https://openai.com/index/gpt-4-1/},
  note         = {Accesat: Iunie 2025}
}

@article{r1,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={DeepSeek-AI et al.},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025},
  month ={January},
  url={https://arxiv.org/abs/2501.12948}
}

@article{v3,
  author    = {DeepSeek-AI et al.},
  title     = {DeepSeek-V3 Technical Report},
  journal   = {arXiv preprint arXiv:2412.19437},
  year      = {2024},
  month     = {December},
  url       = {https://arxiv.org/abs/2412.19437}
}

@inproceedings{cot,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = {Chain-of-thought prompting elicits reasoning in large language models},
year = {2022},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {1800},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}


@inproceedings{golchin,
    title = "Grading Massive Open Online Courses Using Large Language Models",
    author = "Golchin, Shahriar  and
      Garuda, Nikhil  and
      Impey, Christopher  and
      Wenger, Matthew",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.263/",
    pages = "3899--3912",
    abstract = "Massive open online courses (MOOCs) offer free education globally. Despite this democratization of learning, the massive enrollment in these courses makes it impractical for an instructor to assess every student{'}s writing assignment. As a result, peer grading, often guided by a straightforward rubric, is the method of choice. While convenient, peer grading often falls short in terms of reliability and validity. In this study, we explore the feasibility of using large language models (LLMs) to replace peer grading in MOOCs. To this end, we adapt the zero-shot chain-of-thought (ZCoT) prompting technique to automate the feedback process once the LLM assigns a score to an assignment. Specifically, to instruct LLMs for grading, we use three distinct prompts based on ZCoT: (1) ZCoT with instructor-provided correct answers, (2) ZCoT with both instructor-provided correct answers and rubrics, and (3) ZCoT with instructor-provided correct answers and LLM-generated rubrics. We tested these prompts in 18 different scenarios using two LLMs{---}GPT-4 and GPT-3.5{---}across three MOOCs: Introductory Astronomy, Astrobiology, and the History and Philosophy of Astronomy. Our results show that ZCoT, when augmented with instructor-provided correct answers and rubrics, produces grades that are more aligned with those assigned by instructors compared to peer grading. Finally, our findings indicate a promising potential for automated grading systems in MOOCs, especially in subjects with well-defined rubrics, to improve the learning experience for millions of online learners worldwide."
}

